{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install mtcnn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8_EWjS5sjRDq",
        "outputId": "f0a11543-b43d-4592-a1ef-feb1cf9b70b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mtcnn\n",
            "  Downloading mtcnn-0.1.1-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from mtcnn) (2.15.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from mtcnn) (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python>=4.1.0->mtcnn) (1.25.2)\n",
            "Installing collected packages: mtcnn\n",
            "Successfully installed mtcnn-0.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jD6JYjiRjbDr"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import dlib\n",
        "import matplotlib.pyplot as plt\n",
        "from mtcnn import MTCNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "Mpk3EmW5hY0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the MTCNN face detection model\n",
        "mtcnn = MTCNN()"
      ],
      "metadata": {
        "id": "5cQUCrtNh_nT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to detect skin regions in an image\n",
        "def skin_detection(image):\n",
        "    # Convert the image to YCrCb color space\n",
        "    ycrcb = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)\n",
        "\n",
        "    # Define lower and upper thresholds for skin color in YCrCb space\n",
        "    lower = np.array([0, 135, 85], dtype=np.uint8)\n",
        "    upper = np.array([255, 180, 135], dtype=np.uint8)\n",
        "\n",
        "    # Create a binary mask to detect skin regions\n",
        "    mask = cv2.inRange(ycrcb, lower, upper)\n",
        "\n",
        "    # Apply morphological operations to remove noise\n",
        "    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (3, 3))\n",
        "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN, kernel, iterations=2)\n",
        "    mask = cv2.dilate(mask, kernel, iterations=1)\n",
        "\n",
        "    return mask"
      ],
      "metadata": {
        "id": "XRXvt12Uj0dA"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to process skin regions in an image\n",
        "def process_skin_regions(image):\n",
        "    # Detect skin regions in the image\n",
        "    skin_mask = skin_detection(image)\n",
        "\n",
        "    # Extract the skin regions using the mask\n",
        "    skin_regions = cv2.bitwise_and(image, image, mask=skin_mask)\n",
        "\n",
        "    return skin_regions"
      ],
      "metadata": {
        "id": "2MR7Vnyfj67b"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_and_process_skin(image_path, output_folder):\n",
        "    # Read the input image\n",
        "    img = cv2.imread(image_path)\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Extract the class label from the image path\n",
        "    class_label = os.path.basename(os.path.dirname(image_path))\n",
        "\n",
        "    # Create the class output folder if it doesn't exist\n",
        "    class_output_folder = os.path.join(output_folder, class_label)\n",
        "    os.makedirs(class_output_folder, exist_ok=True)\n",
        "\n",
        "    # Detect faces in the image\n",
        "    detections = mtcnn.detect_faces(img_rgb)\n",
        "\n",
        "    # Check if any faces were detected\n",
        "    if detections:\n",
        "        # Extract the first detected face\n",
        "        x, y, width, height = detections[0]['box']\n",
        "\n",
        "        # Crop the face region\n",
        "        face_img = img[y:y+height, x:x+width]\n",
        "\n",
        "        # Process skin regions within the cropped face image\n",
        "        processed_skin_image = process_skin_regions(face_img)\n",
        "\n",
        "        # Save the processed skin image in the class output folder\n",
        "        output_skin_path = os.path.join(class_output_folder, f\"processed_skin_{os.path.basename(image_path)}\")\n",
        "        cv2.imwrite(output_skin_path, processed_skin_image)\n",
        "        print(f\"Processed skin image saved successfully: {output_skin_path}\")\n",
        "        return True\n",
        "    else:\n",
        "        print(f\"No faces were detected in the image: {image_path}\")\n",
        "        # If no faces are detected, extract skin regions or save the original image\n",
        "        skin_mask = skin_detection(img)\n",
        "        if np.any(skin_mask):\n",
        "            # Extract skin regions using the mask\n",
        "            skin_regions = cv2.bitwise_and(img, img, mask=skin_mask)\n",
        "            output_skin_path = os.path.join(class_output_folder, f\"processed_skin_{os.path.basename(image_path)}\")\n",
        "            cv2.imwrite(output_skin_path, skin_regions)\n",
        "            print(f\"Processed skin image saved successfully: {output_skin_path}\")\n",
        "        else:\n",
        "            # Save the original image if no skin regions are detected\n",
        "            output_original_path = os.path.join(class_output_folder, f\"original_{os.path.basename(image_path)}\")\n",
        "            cv2.imwrite(output_original_path, img)\n",
        "            print(f\"No skin regions detected. Original image saved: {output_original_path}\")\n",
        "        return False\n"
      ],
      "metadata": {
        "id": "cZAvjbA5uJ8u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to process a set of images\n",
        "def process_images(image_paths, output_folder):\n",
        "    for i, image_path in enumerate(image_paths):\n",
        "        detect_and_process_skin(image_path, output_folder)\n",
        "\n",
        "# Path to the input folder in Google Drive\n",
        "input_folder = '/content/drive/My Drive/Dataset'\n",
        "# Path to the output folder in Google Drive\n",
        "output_folder = '/content/drive/My Drive/Processed_Images'\n",
        "\n",
        "# List files in the input folder\n",
        "import os\n",
        "image_files = [os.path.join(input_folder, f) for f in os.listdir(input_folder) if f.endswith(('.jpg', '.jpeg', '.png'))]\n",
        "\n",
        "# Process the images\n",
        "process_images(image_files, output_folder)"
      ],
      "metadata": {
        "id": "9wgM9s2Jh7m1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}